{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMJH5mQ8lOBhNCfOpUFKIfE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/malshaikh03/ANN-Lab/blob/main/Untitled4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIWa_zTaat-c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from tensorflow import keras    \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, RandomCrop, GlobalAveragePooling2D, MaxPool2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from imblearn.over_sampling import RandomOverSampler \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os, cv2\n",
        "from PIL import Image\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from tensorflow.keras.applications import efficientnet_v2 , EfficientNetB3\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# The next line for using GPU through CUDA core for computitation\n",
        "# Comment all lines if you don't have NVIDIA CUDA GPU \n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "if len(physical_devices) > 0:\n",
        "    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Don't run if you run locally\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "bnsfQTzg2_rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "images_names = os.listdir('/content/gdrive/MyDrive/Skin-Cancer-MNIST-HAM10000/Capstone_Project-main/HAM10000_images')\n",
        "\n",
        "newlist = []\n",
        "for imagename in images_names:\n",
        "    newlist.append(str('/content/gdrive/MyDrive/Skin-Cancer-MNIST-HAM10000/Capstone_Project-main/HAM10000_images/'+imagename))\n",
        "# Load the meta data and store on dataframe\n",
        "df = pd.read_csv('/content/gdrive/MyDrive/Skin-Cancer-MNIST-HAM10000/Capstone_Project-main/HAM10000_metadata.csv')\n",
        "\n",
        "# sort the data frame\n",
        "df = df.sort_values('image_id').reset_index()\n",
        "# add new column to the dataframe and store images path/name on it\n",
        "df['image_path'] = pd.DataFrame(newlist).sort_values()\n",
        "\n",
        "# load the image onto dataframe\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "CRHepRGrcEwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the image_path \n",
        "df1 = df['image_path']\n",
        "df1 = df1.sort_values().reset_index()\n",
        "df1.columns=['index','image_path']\n",
        "df['image_path'] = df1['image_path']"
      ],
      "metadata": {
        "id": "es0ztrBy7f1y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the image and resize it onto 300x300\n",
        "df['image'] = df['image_path'].map(lambda x: np.asarray(Image.open(x).resize((300,300))))"
      ],
      "metadata": {
        "id": "7FCKepu7Wczp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dfdup = df[df['dx']!='nv']"
      ],
      "metadata": {
        "id": "jtZGV3h1hW0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make image to an array\n",
        "X = np.asarray(df['image'].tolist())"
      ],
      "metadata": {
        "id": "QDVf_vjW3r-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "y = df.dx\n",
        "y_labelencoder = LabelEncoder ()\n",
        "y = y_labelencoder.fit_transform (y)\n",
        "y.shape"
      ],
      "metadata": {
        "id": "IY720cv47jIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save the target in dict\n",
        "ycode = y_labelencoder.transform(y_labelencoder.classes_)\n",
        "yclass = y_labelencoder.classes_\n",
        "ydict = {}\n",
        "for key,value in zip(ycode,yclass):\n",
        "  ydict[key]=value\n",
        "ydict"
      ],
      "metadata": {
        "id": "qJoXhwoedAPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one hot encoding \n",
        "y = to_categorical(y, num_classes = 7)\n"
      ],
      "metadata": {
        "id": "7QR5Uubw7mUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "X, y = shuffle(X, y, random_state=1)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2, random_state=1)"
      ],
      "metadata": {
        "id": "Svl0GwOh7pPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(num_classes):\n",
        "    inputs = layers.Input(shape=(300, 300, 3))\n",
        "\n",
        "    model = efficientnet_v2.EfficientNetV2B3(include_top=False, \n",
        "                                             weights=\"imagenet\", input_shape=(300,300,3),\n",
        "                                             input_tensor=inputs\n",
        "                                            )\n",
        "\n",
        "    # Freeze the pretrained weights\n",
        "    model.trainable = False\n",
        "\n",
        "    # Rebuild top\n",
        "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "\n",
        "    top_dropout_rate = 0.2\n",
        "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
        "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
        "\n",
        "    # Compile\n",
        "    model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "ATeYuoB57q2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callback = tf.keras.callbacks.ModelCheckpoint(filepath='callbackHAM_Model.h5',\n",
        "                                                  monitor='val_acc', mode='max',\n",
        "                                                 verbose=1)"
      ],
      "metadata": {
        "id": "iXgeybJW9gZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(num_classes=7)\n",
        "epochs = 20\n"
      ],
      "metadata": {
        "id": "SHdWj1d57x_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train,\n",
        "                    Y_train,\n",
        "                    batch_size = 128,\n",
        "                    epochs = 20,\n",
        "                    callbacks=[callback])"
      ],
      "metadata": {
        "id": "suOVH-OE9lTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning the model\n",
        "def unfreeze_model(model):\n",
        "    # We unfreeze the top 20 layers while leaving BatchNorm layers frozen\n",
        "    for layer in model.layers[-20:]:\n",
        "        if not isinstance(layer, layers.BatchNormalization):\n",
        "            layer.trainable = True\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "\n",
        "unfreeze_model(model)\n"
      ],
      "metadata": {
        "id": "SD_3oDk9_BQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model after unfreaze and fine Tuning\n",
        "hist = model.fit(X_train, Y_train, epochs=10)"
      ],
      "metadata": {
        "id": "1zKHmKeKaMF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('my_model4/my_model.h5')"
      ],
      "metadata": {
        "id": "NOxBE43QqIxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g_ZWBMUd0GRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.saving.legacy.save import load_model\n",
        "save_model = load_model('my_model4/my_model.h5')"
      ],
      "metadata": {
        "id": "iLtY1ZXhhq1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model X_test,Y_test and print the loss and accuracy\n",
        "score = save_model.evaluate(X_test, Y_test)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "id": "xiX_Cd1vjNVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load sample image for testing and resize image and change it to np.array\n",
        "def load_image(image_path):\n",
        "  image = Image.open(image_path)\n",
        "  image = image.resize((300, 300))\n",
        "  imgarray = np.asarray(image)\n",
        "  return image , imgarray\n"
      ],
      "metadata": {
        "id": "mjdsmn_wjf-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image, img = load_image('/content/gdrive/MyDrive/Skin-Cancer-MNIST-HAM10000/Capstone_Project-main/HAM10000_images/ISIC_0024318.jpg')\n",
        "image\n",
        "img.shape"
      ],
      "metadata": {
        "id": "boM3g2bEkO_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(np.array([img]))\n",
        "\n",
        "prediction"
      ],
      "metadata": {
        "id": "0Srmt0Znr-H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ydict"
      ],
      "metadata": {
        "id": "OBjhSYMSocb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[12]"
      ],
      "metadata": {
        "id": "adER2K9Pw1Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Model predicts correctly"
      ],
      "metadata": {
        "id": "kg-1skb4w56D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}